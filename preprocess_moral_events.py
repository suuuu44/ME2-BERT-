# -*- coding: utf-8 -*-
"""
MoralEvents JSON -> CSVï¼ˆè¯å…¸æ³•æƒ…ç»ªï¼‰
- è‹¥æœªæä¾› --nrc_lex_pathï¼Œå°†è‡ªåŠ¨åœ¨å¸¸è§ç›®å½•æŸ¥æ‰¾ï¼›è‹¥æ— åˆ™å°è¯•ä¸‹è½½åˆ° ./data/lexicons/ã€‚
è¾“å‡ºåˆ—ï¼š
  article_id, para_id, text, event(json), domain(0/1),
  care, fairness, loyalty, authority, purity,
  anger, fear, joy, sadness, surprise, disgust, anticipation, trust,
  no_emotion
"""
import os
import json
import glob
import argparse
from pathlib import Path
from collections import defaultdict, Counter

import pandas as pd
from tqdm import tqdm

# -----------------------------
# è‡ªåŠ¨å®šä½ / ä¸‹è½½ NRC è¯å…¸
# -----------------------------
CANDIDATE_URLS = [
    # è¿™ä¸¤ä¸ªé•œåƒå¯èƒ½å¤±æ•ˆï¼›è„šæœ¬ä¼šæç¤ºæ‰‹åŠ¨æ”¾ç½®
    "https://raw.githubusercontent.com/ishikota/NRC-Emotion-Lexicon-Wordlevel/master/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt",
    "https://raw.githubusercontent.com/wwbp/lexica/master/NRC-Emotion-Lexicon-v0.92/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt",
]

DEFAULT_LEX_DIR = Path("./data/lexicons")
DEFAULT_LEX_NAME = "NRC-Emotion-Lexicon-Wordlevel-v0.92.txt"

def ensure_lexicon(lex_path_arg: str | None) -> Path:
    """ä¼˜å…ˆä½¿ç”¨ä¼ å…¥è·¯å¾„ï¼›å¦åˆ™åœ¨å¸¸è§ç›®å½•å¯»æ‰¾ï¼›å†ä¸è¡Œå°è¯•ä¸‹è½½ã€‚"""
    if lex_path_arg:
        p = Path(lex_path_arg)
        if p.is_file():
            return p
        raise FileNotFoundError(f"æŒ‡å®šçš„ lexicon ä¸å­˜åœ¨: {p}")

    candidates = [
        DEFAULT_LEX_DIR / DEFAULT_LEX_NAME,
        Path("./") / DEFAULT_LEX_NAME,
    ]
    for c in candidates:
        if c.is_file():
            return c

    DEFAULT_LEX_DIR.mkdir(parents=True, exist_ok=True)
    dst = DEFAULT_LEX_DIR / DEFAULT_LEX_NAME
    try:
        import requests
        for url in CANDIDATE_URLS:
            try:
                print(f"â¬‡ï¸  å°è¯•ä¸‹è½½ NRC è¯å…¸: {url}")
                r = requests.get(url, timeout=30)
                if r.status_code == 200 and len(r.text) > 1024:
                    with open(dst, "w", encoding="utf-8") as f:
                        f.write(r.text)
                    print(f"âœ… å·²ä¸‹è½½: {dst}")
                    return dst
                else:
                    print(f"âš ï¸ ä¸‹è½½å¤±è´¥/å†…å®¹å¼‚å¸¸ï¼ˆstatus={r.status_code}ï¼‰ï¼Œå°è¯•ä¸‹ä¸€ä¸ªé•œåƒ...")
            except Exception as e:
                print(f"âš ï¸ ä¸‹è½½å‡ºé”™: {e}ï¼Œå°è¯•ä¸‹ä¸€ä¸ªé•œåƒ...")
        raise RuntimeError("æ‰€æœ‰é•œåƒå‡æœªæˆåŠŸã€‚è¯·æ‰‹åŠ¨æ”¾ç½®è¯å…¸æ–‡ä»¶ã€‚")
    except ImportError:
        raise RuntimeError(
            "æœªæ‰¾åˆ° NRC è¯å…¸ï¼Œä¸”æœªå®‰è£… requests æ— æ³•è‡ªåŠ¨ä¸‹è½½ã€‚\n"
            f"è¯·æ‰‹åŠ¨ä¸‹è½½ {DEFAULT_LEX_NAME} åˆ° {DEFAULT_LEX_DIR.resolve()}ï¼Œæˆ–é€šè¿‡ --nrc_lex_path æŒ‡å®šè·¯å¾„ã€‚"
        )

# -----------------------------
# è¯å…¸è¯»å– & æ‰“åˆ†
# -----------------------------
EMO8 = ['anger','fear','joy','sadness','surprise','disgust','anticipation','trust']

def load_nrc_lexicon(lex_path, lowercase=True):
    """æ”¯æŒå®˜æ–¹ .txtï¼ˆä¸‰åˆ—ï¼šword emotion assocï¼‰ã€‚è‹¥æ˜¯ .csvï¼Œéœ€å« word + 8æƒ…ç»ªåˆ—ã€‚"""
    lex = defaultdict(lambda: {e: 0.0 for e in EMO8})
    lex_path = Path(lex_path)
    if lex_path.suffix.lower() == ".csv":
        df = pd.read_csv(lex_path)
        cols = {c.lower().strip(): c for c in df.columns}
        word_col = cols.get('word', None)
        if word_col is None:
            raise ValueError("CSV éœ€åŒ…å« 'word' åˆ—")
        for e in EMO8:
            if e not in cols:
                raise ValueError(f"CSV ç¼ºå°‘æƒ…ç»ªåˆ—: {e}")
        for _, row in df.iterrows():
            w = str(row[word_col])
            if lowercase: w = w.lower()
            for e in EMO8:
                val = float(row[cols[e]])
                if val > 0:
                    lex[w][e] = val
    else:
        with open(lex_path, 'r', encoding='utf-8') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) < 3:
                    continue
                w, emo, assoc = parts[0], parts[1].lower(), parts[2]
                if emo not in EMO8:
                    continue
                if lowercase: w = w.lower()
                try:
                    a = float(assoc)
                except:
                    a = 0.0
                if a > 0:
                    lex[w][emo] = a
    return dict(lex)

def score_emotions_by_lex(text, lex, lowercase=True):
    """æœ€ç®€è¯é¢‘åŠ æ€»â†’æ€»å’Œå½’ä¸€åŒ–ï¼›å¯æ›¿æ¢ä¸ºæ›´å¤æ‚çš„æ¸…æ´—/è¯å½¢è¿˜åŸã€‚"""
    if not isinstance(text, str) or len(text.strip()) == 0:
        return {e: 0.0 for e in EMO8}
    t = text.lower() if lowercase else text
    tokens = []
    for w in t.split():
        w = ''.join([ch for ch in w if ch.isalpha()])
        if w:
            tokens.append(w)
    if not tokens:
        return {e: 0.0 for e in EMO8}
    counts = Counter()
    for w in tokens:
        if w in lex:
            for e, sc in lex[w].items():
                counts[e] += sc
    total = sum(counts.values())
    if total <= 0:
        return {e: 0.0 for e in EMO8}
    return {e: float(counts[e]) / total for e in EMO8}

# -----------------------------
# é“å¾·æ ‡ç­¾ 10->5 åˆå¹¶
# -----------------------------
MORAL_POS = ['care','fairness','loyalty','authority','purity']
MORAL_VICE = {
    'care': 'harm',
    'fairness': 'cheating',
    'loyalty': 'betrayal',
    'authority': 'subversion',
    'purity': 'degradation'
}
def morals_to_5pos(moral_labels):
    y = {m: 0.0 for m in MORAL_POS}
    for lab in moral_labels:
        if not lab:
            continue
        s = str(lab).strip().lower()
        if s in MORAL_POS:
            y[s] = 1.0
        else:
            for pos, neg in MORAL_VICE.items():
                if s == neg:
                    y[pos] = 1.0
    return y

# -----------------------------
# ä¸»æµç¨‹
# -----------------------------
def main(input_dir, output_csv, nrc_lex_path=None):
    lex_file = ensure_lexicon(nrc_lex_path)
    print(f"ğŸ§© ä½¿ç”¨ NRC è¯å…¸: {lex_file}")
    lex = load_nrc_lexicon(lex_file, lowercase=True)
    print(f"âœ… Loaded lexicon: {len(lex)} words")

    rows = []
    files = sorted(glob.glob(os.path.join(input_dir, "*.json")))
    print(f"ğŸ“‚ Found {len(files)} JSON documents")

    for file in tqdm(files, desc="Parsing JSON"):
        with open(file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        article_id = Path(file).stem
        news_paragraphs = {n['id']: (n.get('text','') or '').strip() for n in data.get("news", [])}

        para_events = defaultdict(list)
        para_morals = defaultdict(list)

        for ann in data.get("annotations", []):
            para_id = ann.get("para")
            if para_id is None:
                continue
            event_info = {
                "mention": ann.get("event", ""),
                "trigger": ann.get("event_trigger", ""),
                "entities": {}
            }
            for k in ["agent","patient","agent2","patient2","agent3","patient3"]:
                if ann.get(k):
                    role = "agent" if "agent" in k else "patient"
                    event_info["entities"][ann[k]] = role
            para_events[para_id].append(event_info)
            morals = [ann.get("morality"), ann.get("morality2"), ann.get("morality3")]
            para_morals[para_id].extend([m for m in morals if m])

        for pid, text in news_paragraphs.items():
            ev_list = para_events.get(pid, [])
            y5 = morals_to_5pos(para_morals.get(pid, []))
            domain_label = 1 if len(ev_list) > 0 else 0
            emo_scores = score_emotions_by_lex(text, lex, lowercase=True)

            # æ ‡è®° no_emotionï¼ˆä¾›å¯¹æ¯”å­¦ä¹ æ©ç ä½¿ç”¨ï¼‰
            noemo = 1.0 if sum(emo_scores.values()) == 0 else 0.0
            emo_scores["no_emotion"] = noemo

            rows.append({
                "article_id": article_id,
                "para_id": pid,
                "text": text,
                "event": json.dumps(ev_list, ensure_ascii=False),
                "domain": domain_label,
                **y5,
                **emo_scores
            })

    df = pd.DataFrame(rows)
    Path(output_csv).parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(output_csv, index=False, encoding='utf-8-sig')
    print(f"\nâœ… Done. Saved {len(df)} rows -> {output_csv}")
    print("Columns:", list(df.columns))

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input_dir", type=str, default="./data/MoralEvents/articles",
                        help="Path to MoralEvents articles/*.json")
    parser.add_argument("--output_csv", type=str, default="./data/moral_events_lex.csv",
                        help="Output CSV path")
    parser.add_argument("--nrc_lex_path", type=str, default=None,
                        help="Path to NRC/EmoLex (txt/csv). è‹¥ä¸æä¾›ï¼Œå°†è‡ªåŠ¨æŸ¥æ‰¾/ä¸‹è½½ã€‚")
    args = parser.parse_args()
    main(args.input_dir, args.output_csv, args.nrc_lex_path)
